# ü§ñ SageBot  ‚Äî Desafio de NLP 

O **SageBot RAG** √© um chatbot inteligente desenvolvido como solu√ß√£o para o **Desafio de NLP**, unindo **LangChain**, **OpenAI Embeddings** e **Streamlit** em uma arquitetura de **RAG (Retrieval-Augmented Generation)**.

Ele permite enriquecer as respostas do modelo com **conte√∫do contextual** proveniente de documentos **Markdown (.md)**, **PDFs** ou **URLs**, criando um **assistente t√©cnico contextualizado** ‚Äî ideal para responder d√∫vidas baseadas em bases documentais.

---

## üß† Objetivo do projeto

O projeto foi desenvolvido como parte do **Desafio de Processamento de Linguagem Natural (NLP)**, com foco em:

- Implementar um pipeline **RAG completo**;
- Aplicar **embeddings sem√¢nticos** via OpenAI;
- Integrar **LLMs configur√°veis (OpenAI / Groq)**;
- Exibir **status em tempo real** da indexa√ß√£o;
- Oferecer uma interface **simples e interativa via Streamlit**.

---

## ‚öôÔ∏è Pr√©-requisitos obrigat√≥rios

Para o funcionamento do chatbot, o usu√°rio **deve obrigatoriamente**:

1. **Escolher uma fonte de conhecimento**, que ser√° usada para enriquecer o contexto do chat:  
   - Arquivos **Markdown (.md)**  
   - Arquivos **PDF (.pdf)**  
   - Ou uma **URL** de um site/documenta√ß√£o p√∫blica  

2. **Selecionar o modelo de LLM** que ser√° utilizado:  
   - **OpenAI** ‚Üí `gpt-4o`, `gpt-4.1-nano`  
   - **Groq** ‚Üí `llama-3.1-8b-instant`, `llama-3.3-70b-versatile`  

3. **Inserir sua chave pessoal (API Key)** do provedor escolhido:
   - `OPENAI_API_KEY` ou `GROQ_API_KEY`

4. **Escolher o modelo de embeddings OpenAI** (obrigat√≥rio):
   - `text-embedding-3-small` *(mais r√°pido e barato)*  
   - `text-embedding-3-large` *(melhor precis√£o sem√¢ntica)*  

Sem esses quatro passos, o chatbot **n√£o funcionar√° corretamente**.

---

## üß© Arquitetura do projeto

```
sagebot-rag/
‚îú‚îÄ‚îÄ app.py               # Interface principal (Streamlit)
‚îú‚îÄ‚îÄ loader.py            # Carregamento de MD, PDF e URLs
‚îú‚îÄ‚îÄ rag.py               # Split, embeddings e FAISS
‚îú‚îÄ‚îÄ work_rag.py          # Thread de indexa√ß√£o + cache
‚îú‚îÄ‚îÄ progress.py          # Controle de progresso e logs
‚îú‚îÄ‚îÄ utils.py             # Fun√ß√µes auxiliares (hash de documentos)
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example         # Modelo de vari√°veis de ambiente
‚îú‚îÄ‚îÄ Dockerfile           # Configura√ß√£o Docker
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ index/           # Cache FAISS persistente
```
---

## üß± Instala√ß√£o local (modo desenvolvedor)

1Ô∏è‚É£ **Clonar o reposit√≥rio**
```bash
git clone https://github.com/seuusuario/sagebot-rag.git
cd sagebot-rag
```

2Ô∏è‚É£ **Criar ambiente virtual**
```bash
python -m venv .venv
.env\Scriptsctivate     # Windows
# ou
source .venv/bin/activate   # Linux/Mac
```

3Ô∏è‚É£ **Instalar depend√™ncias**
```bash
pip install -r requirements.txt
```

4Ô∏è‚É£ **Rodar a aplica√ß√£o**
```bash
streamlit run app.py
```

5Ô∏è‚É£ **Acessar**
üëâ [http://localhost:8501](http://localhost:8501)

---

## üåê Passo a passo para usar o chatbot (interface web)

### üß© 1. Carregar o contexto
No menu lateral (sidebar):
- Escolha **um tipo de arquivo** (obrigat√≥rio): `.md`, `.pdf` ou `url`
- Fa√ßa upload do(s) arquivo(s) ou cole a URL desejada

### ‚öôÔ∏è 2. Selecionar o modelo
- Selecione o provedor: **OpenAI** ou **Groq**
- Escolha o modelo de linguagem (LLM)
- Insira sua **API Key pessoal** correspondente

### üß† 3. Configurar embeddings
- Escolha o modelo de embedding:  
  `text-embedding-3-small` ou `text-embedding-3-large`
- Ajuste o par√¢metro **Top-K** (quantos resultados similares ser√£o buscados no RAG)

### üöÄ 4. Inicializar o SageBot
- Clique no bot√£o **‚ÄúInicializar SageBot‚Äù**
- Acompanhe o progresso da indexa√ß√£o (split ‚Üí embed ‚Üí index ‚Üí ready)

### üí¨ 5. Conversar
- Ap√≥s o status indicar **‚Äú√çndice RAG pronto ok.‚Äù**, digite sua pergunta.
- O bot responder√° com base no contexto carregado.
- Se desejar, clique em **‚ÄúApagar Hist√≥rico de Conversa‚Äù** para reiniciar.

---

## üê≥ Execu√ß√£o com Docker

### 1Ô∏è‚É£ Construir imagem
```bash
docker build -t sagebot-rag .
```

### 2Ô∏è‚É£ Rodar container
```bash
docker run -p 8501:8501 --env-file .env sagebot-rag
```

### 3Ô∏è‚É£ Persistir cache FAISS
```bash
docker run -p 8501:8501   --env-file .env   -v $(pwd)/data:/app/data   sagebot-rag
```

> Acesse em: [http://localhost:8501](http://localhost:8501)

---

## ‚ö°Ô∏è Fluxo t√©cnico interno

1. **Entrada:** usu√°rio envia documentos (.md, .pdf) ou URL.  
2. **Split:** o texto √© segmentado com `RecursiveCharacterTextSplitter`.  
3. **Embeddings:** vetores criados com `OpenAIEmbeddings`.  
4. **Indexa√ß√£o:** FAISS cria e salva o √≠ndice vetorial (`data/index/<hash>`).  
5. **Retriever:** busca sem√¢ntica recupera os `k` trechos mais similares.  
6. **LLM:** modelo selecionado (OpenAI/Groq) gera resposta contextual.  
7. **UI:** progresso mostrado em tempo real via `progress.py`.

---

## üß† Dicas de performance

| Par√¢metro | Descri√ß√£o |
|------------|------------|
| `chunk_size=1500` | √≥timo equil√≠brio entre custo e recall |
| `batch_size=64` | evita erro de limite de tokens |
| `text-embedding-3-small` | recomendado para builds r√°pidos |
| `Top-K=4` | resultados mais relevantes e concisos |
| **Cache FAISS** | reduz tempo de indexa√ß√£o e custo de tokens |

---

## üß∞ Troubleshooting

| Erro | Causa | Solu√ß√£o |
|------|--------|----------|
| `OPENAI_API_KEY inv√°lida` | Chave incorreta | Corrigir no `.env` |
| `Rate limit excedido` | Muitas chamadas √† API | Aguardar alguns segundos |
| `Requested 302912 tokens...` | Texto muito grande | Ajustar chunk_size ou batch_size |
| `FAISS desatualizado` | Vers√£o incompat√≠vel | `pip install --upgrade faiss-cpu` |
| `Streamlit travando` | Chamada de UI na thread errada | Use `render_status()` apenas no main thread |

---

## ‚ú® Cr√©ditos

Desenvolvido por **Mario Jorge Lira de Lima Junior**  

üìç *Manaus ‚Äî AM*  

Projeto desenvolvido como entrega oficial do **Desafio de NLP** (Laborat√≥rio de Sistemas Inteligentes ‚Äì LSE).
